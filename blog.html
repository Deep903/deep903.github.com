<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>UFO Search Blog</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link href="https://fonts.googleapis.com/css?family=Montserrat&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <a href="/index.html#proposal-cut" class="btn btn-primary">Back</a>

    <section id="blog">
            <div class="jumbotron jumbotron-fluid">
              <div class="container">
                <h1 class="display-3">UFO Project Blog</h1>
                <h1>Search Feature</h1>
                <hr>
                <h1>Reference</h1>
                <p class="lead">The reference used in this project<a id='blog_ref' href="https://www.youtube.com/watch?v=jpupXhZ92c8&list=PLy0R06Fv9ZSIHjFje2d53WztJeNjHW0zT" class="btn btn-primary">Is located here!</a></p>
                <p class='lead'>Contribution over this reference involves implementing file saving to save the TF-IDF values so that they do not need to be calculated every time the program runs. This improves the programs efficiently greatly!</p>
                <p class='lead'>Additionally, the reference only gives an idea of how to do the TF-IDF calculation in python. Calculating document scores and ranking was all done by me. As well as taking in user input, and giving output.</p>
                <hr>
                <h1>Challenge</h1>
                <p class='lead'>I had a few big challenges while creating this project. For example, deployment to the web, using python for the first time, and even file reading. My biggest problem however, was using Flask for the first time. To solve this issue, I extensively read the documentation on Flask along with various answers on sites like stack overflow. Input and output in flask was particularly hard for my to figure out until I read up enough information online. It does not work the same way as It does in javascript.</p>
                <hr>
                <h1>Algorithms (Basics)</h1>
                <p class='lead'>First, term frequency (count of terms in a document) is calculated. Then the inverse document frequency (which is a number that represents how much a term is valued at) is calculated. Lastly, the two values are multiplied to give the TF-IDF values of every word in a document. When given a query, words in the query can be searched for in every document. When found, its TF-IDF score is added up. The documents with the highest summations are the relevant ones.</p>
                <p class='lead'>For ranking the document, every document is scanned for the query words. If a query word is found, its TF-IDF value is added to a sum. Documents are then ranked by sum. Thus, documents that have words with high TF-IDF scores matching the query will be ranked highly.</p>
                <hr>

                <br>
                <h1>Classifier Feature</h1>
                <hr>
                <h1>Reference</h1>
                <p class="lead">The reference used in this project<a id='blog_ref' href="https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/" class="btn btn-primary">Is located here!</a></p>
                <p class='lead'>There were a few contributions over the reference material. To start, the reference only shows how to build the model, using the model was implemented by me. Additionally, user input was also added. That way queries could be processed and classified appropriately using the model. Figuring out how to output all the classification probabilities to flask was another challenge.</p>
                <hr>
                <h1>Challenge</h1>
                <p class='lead'>Major challenges included a lack of machine learning knowledge, and lack of which model would be best, and again struggles with using python/flask. The reference helped greatly by explaining how naive bayes worked, particularly in python programming. I went with a Naive Bayes classifier because it seemed accurate and easy to implement. The python struggles were much less now that I have been working in it for a while. When I ran into an issue, I simply looked at documentation for the answer.</p>
                <hr>
                <h1>Algorithms (Basics)</h1>
                <p class='lead'>The dataset is first split into parts. A 70% training set and a 30% test set.</p>
                <p class='lead'>Next, the model is built using the data from the training set. Naive Bayes uses probability to classify items. Thus, the model is essentially the relationship between a documents contents and it's classifier. For the classifier, we are classifying the shapes of UFO's. </p>
                <p class='lead'>The end result is that the model can take the TF-IDF of a query and find the probability that it is a given shape. In fact, Naive Bayes finds the probability of all possible classifications, and choses the one with the highest probability. Naive Bayes essentially gives the P(x|y) where x is a classification, and y is the contents of the query.</p>
                <hr>
                <h1>Evaluation</h1>
                <p class='lead'>Using the testing dataset, it is possible to see how accurate the model truly is. In my testing, the accuracy of the model was 42.56%. While this may seem low, I believe I have found the reason. The actual 'shape' catagories can be very ambiguous. For example, 'circle', 'sphere', and 'fireball' are all very similar so it is easy for the model to make a mistake. So even though the model is 'wrong' using the test data. In practice it is pretty close most of the time. The final model actually combines the previously mentioned classifications into one. There was also the added problem that I was lacking enough data for some of the classifications. For example, very few records were classified as "cigar", so it made classifying a cigar shaped UFO hard to do.</p>
                <hr>

                <br>
                <h1>Image Search Feature</h1>
                <hr>
                <h1>Reference</h1>
                <p class="lead">The reference used in this project<a id='blog_ref' href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/image_captioning.ipynb#scrollTo=9Psd1quzaAWg" class="btn btn-primary">Is located here!</a></p>
                <p class='lead'>The reference used is a Jupyter notebook hosted on google colab. After learning how the reference worked by reading the comments, some of the code had to be modified. For starters, the notebook would only caption a single image, so the code had to be modified to caption many images within my google drive. Next, the generated image captions, as well as the filenames for their respective images had to be saved. This was done by importing pickle and saving the variables on the notebook right into drive. From there, code from the first feature was used to TF-IDF search the captions. Additional code was added to allow for displaying images.</p>
                <hr>
                <h1>Challenge</h1>
                <p class='lead'>Major challenges include lack of experience with Jupyter notebook as well as google cloud. The two previous parts of the project have given me a strong foundation in python which allowed me to overcome this barrier.</p>
                <hr>
                <h1>Algorithms (Basics)</h1>
                <p class='lead'>This feature uses a neural network to generate captions. Neural networks work in layers. Each layer has a certain amount of inputs that can either be on or off. Depending on the state of those inputs, the next layer with also set their states to either on or off. This applies for every layer until the output, and allows for very complex learning. This process is actually modeled after how neurons in the brain interact.</p>
                <p class='lead'>In order to function correctly, the neural network needs to be trained with a dataset and captions. The dataset can actually be iterated through more than once in order to improve the model. Every single one of these cycles is called an epoch.</p>
                <hr>
            </div>
            </div>
        </section>
    
</body>
</html>